import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
from metrics import calculate_metrics
import matplotlib.pyplot as plt
import shap

# ==========================
# 1. è¯»å–æ•°æ®
# ==========================
file_path = r''
data = pd.read_excel(file_path, sheet_name='Sheet3')

X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values.reshape(-1, 1)

# ==========================
# 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# ==========================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print(f"ğŸ” è®­ç»ƒé›†å¤§å°: {X_train.shape}, æµ‹è¯•é›†å¤§å°: {X_test.shape}")

# è®¾ç½®å…¨å±€å­—ä½“ï¼ˆä¸­æ–‡ä¸ºå®‹ä½“ï¼Œè‹±æ–‡ä¸º Times New Romanï¼‰
plt.rcParams['font.family'] = ["Times New Roman", "SimSun"]

# ==========================
# 3. å®šä¹‰æœ€ä¼˜è¶…å‚æ•°
# ==========================
best_params = {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.6186386973072221, 'colsample_bytree': 0.6823037142116228}


# ==========================
# 4. è®­ç»ƒæœ€ç»ˆæ¨¡å‹å¹¶è¯„ä¼°
# ==========================
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

y_scaler = StandardScaler()
y_train_scaled = y_scaler.fit_transform(y_train)
y_test_scaled = y_scaler.transform(y_test)

final_xgb_model = xgb.XGBRegressor(**best_params, random_state=42)
final_xgb_model.fit(X_train_scaled, y_train_scaled.ravel())

# å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼ˆç»“æœä¸ºæ ‡å‡†åŒ–åçš„å€¼ï¼‰
xgb_train_preds_scaled = final_xgb_model.predict(X_train_scaled)
xgb_test_preds_scaled = final_xgb_model.predict(X_test_scaled)

# åæ ‡å‡†åŒ–é¢„æµ‹å€¼
xgb_train_preds = y_scaler.inverse_transform(xgb_train_preds_scaled.reshape(-1, 1)).flatten()
xgb_test_preds = y_scaler.inverse_transform(xgb_test_preds_scaled.reshape(-1, 1)).flatten()

# è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ€§èƒ½æŒ‡æ ‡ï¼ˆä½¿ç”¨åŸå§‹å°ºåº¦çš„ yï¼‰
xgb_train_r2, xgb_train_rmse, xgb_train_mae, xgb_train_mape = calculate_metrics(y_train, xgb_train_preds)
xgb_test_r2, xgb_test_rmse, xgb_test_mae, xgb_test_mape = calculate_metrics(y_test, xgb_test_preds)

# æ‰“å°è®­ç»ƒé›†ç»“æœ
print("\n========== Final Performance on Training Set ==========")
print(f"ğŸ“Œ XGBoost - RÂ²: {xgb_train_r2:.4f}, RMSE: {xgb_train_rmse:.4f}, MAE: {xgb_train_mae:.4f}, MAPE: {xgb_train_mape:.4f}")

# æ‰“å°æµ‹è¯•é›†ç»“æœ
print("\n========== Final Performance on Test Set ==========")
print(f"ğŸ“Œ XGBoost - RÂ²: {xgb_test_r2:.4f}, RMSE: {xgb_test_rmse:.4f}, MAE: {xgb_test_mae:.4f}, MAPE: {xgb_test_mape:.4f}")

# è·å–ç‰¹å¾é‡è¦æ€§
importance = final_xgb_model.get_booster().get_score(importance_type='gain')

# å°†ç‰¹å¾é‡è¦æ€§è½¬æ¢ä¸º DataFrame
importance_df = pd.DataFrame(importance.items(), columns=["Feature", "Gain"])
importance_df = importance_df.sort_values(by="Gain", ascending=False)

# ä½¿ç”¨è‡ªå®šä¹‰ç‰¹å¾åç§°æ˜ å°„
feature_names = [
    "UV\u2082\u2085\u2084",  # UVâ‚‚â‚…â‚„
    "DOC",
    "FRI-Regionâ… ", 
    "FRI-Regionâ…¡", 
    "FRI-Regionâ…¢", 
    "FRI-Regionâ…£",
    "FRI-Regionâ…¤", 
    "F\u2098\u2090\u2093-C1",  # Fâ‚˜â‚â‚“-C1
    "F\u2098\u2090\u2093-C2",  # Fâ‚˜â‚â‚“-C2
    "F\u2098\u2090\u2093-C3"   # Fâ‚˜â‚â‚“-C3
]

# æ£€æŸ¥ç‰¹å¾åç§°çš„æ•°é‡ä¸å®é™…ç‰¹å¾æ•°é‡æ˜¯å¦åŒ¹é…
if len(feature_names) != len(importance_df):
    print(f"è­¦å‘Š: ç‰¹å¾åç§°æ•°é‡ï¼ˆ{len(feature_names)}ï¼‰ä¸ç‰¹å¾é‡è¦æ€§æ•°é‡ï¼ˆ{len(importance_df)}ï¼‰ä¸åŒ¹é…")
else:
    # æ›¿æ¢ä¸ºè‡ªå®šä¹‰ç‰¹å¾åç§°
    importance_df["Feature"] = importance_df["Feature"].map(lambda x: feature_names[int(x[1:]) - 1] if x.startswith('f') else x)

# ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾
plt.figure(figsize=(10, 6))
bars = plt.barh(importance_df["Feature"], importance_df["Gain"], color='skyblue')
plt.barh(importance_df["Feature"], importance_df["Gain"], color='skyblue')
plt.xlabel('XGBoostç‰¹å¾é‡è¦æ€§', fontsize=12)
plt.title('XGBoostç‰¹å¾é‡è¦æ€§', fontsize=14)
plt.gca().invert_yaxis()  # åè½¬ y è½´ï¼Œä½¿å¾—æœ€é‡è¦çš„ç‰¹å¾åœ¨ä¸Šé¢

# åœ¨æ¯ä¸ªæ¡å½¢ä¸Šæ·»åŠ æ•°å€¼
for bar in bars:
    plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2,
             f'{bar.get_width():.2f}', va='center', ha='left', fontsize=10)
plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight', pad_inches=0.1)
plt.show()
# ==========================
# 6. SHAP å¯è§£é‡Šæ€§åˆ†æ
# ==========================
explainer = shap.TreeExplainer(final_xgb_model)
shap_values = explainer.shap_values(X_test_scaled)

# --- éªŒè¯ç‰¹å¾åç§°æ•°é‡æ˜¯å¦ä¸ X_test_scaled çš„åˆ—æ•°åŒ¹é… ---
if len(feature_names) != X_test_scaled.shape[1]:
    print(f"è­¦å‘Šï¼šç‰¹å¾åç§°çš„æ•°é‡ ({len(feature_names)}) ä¸ç‰¹å¾æ•°é‡ ({X_test_scaled.shape[1]}) ä¸åŒ¹é…ã€‚")
    # å¦‚æœä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾åç§°
    feature_names = [f"ç‰¹å¾ {i+1}" for i in range(X_test_scaled.shape[1])]

import shap
import matplotlib.pyplot as plt

# è®¡ç®— SHAP å€¼
explainer = shap.TreeExplainer(final_xgb_model)
shap_values = explainer.shap_values(X_test_scaled)

# éªŒè¯ç‰¹å¾åç§°æ•°é‡æ˜¯å¦ä¸ X_test_scaled çš„åˆ—æ•°åŒ¹é…
if len(feature_names) != X_test_scaled.shape[1]:
    print(f"è­¦å‘Šï¼šç‰¹å¾åç§°çš„æ•°é‡ ({len(feature_names)}) ä¸ç‰¹å¾æ•°é‡ ({X_test_scaled.shape[1]}) ä¸åŒ¹é…ã€‚")
    # å¦‚æœä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾åç§°
    feature_names = [f"ç‰¹å¾ {i+1}" for i in range(X_test_scaled.shape[1])]

# ç»˜åˆ¶ SHAP Beeswarm å›¾
plt.figure(figsize=(8, 6))
shap.summary_plot(
    shap_values,
    X_test_scaled,
    feature_names=feature_names,
    plot_type="dot",
    show=False  # ç¦æ­¢è‡ªåŠ¨æ˜¾ç¤º
)
plt.title("SHAP Beeswarm å›¾", fontsize=14)
plt.savefig('shap_beeswarm.png', dpi=300, bbox_inches='tight', pad_inches=0.1)
plt.show()

# --- (3) æ¡å½¢å›¾ï¼ˆæŸ±çŠ¶å›¾ï¼‰ ---
# è·å– SHAP å€¼çš„ç»å¯¹å€¼å’Œå¯¹åº”çš„ç‰¹å¾å
shap_abs_values = np.abs(shap_values).mean(axis=0)  # æ¯ä¸ªç‰¹å¾çš„å¹³å‡ SHAP å€¼
sorted_idx = np.argsort(shap_abs_values)[::-1]  # æŒ‰ç…§ SHAP å€¼å¤§å°é™åºæ’åº
sorted_feature_names = [feature_names[i] for i in sorted_idx]
sorted_shap_values = shap_abs_values[sorted_idx]

# ç»˜åˆ¶å®šåˆ¶æ¡å½¢å›¾
plt.figure(figsize=(6, 8))  # è°ƒæ•´å›¾åƒæ¯”ä¾‹ï¼Œä½¿å…¶æ›´çª„æ›´é«˜
bars = plt.barh(sorted_feature_names, sorted_shap_values, color='steelblue')  # ä½¿ç”¨æ›´æ·±çš„é¢œè‰²
plt.title("SHAP æ¡å½¢å›¾åŠæ•°å€¼", fontsize=14)
plt.xlabel('å¹³å‡ SHAP å€¼ï¼ˆé‡è¦æ€§ï¼‰', fontsize=14)
plt.yticks(fontsize=14)  # è®¾ç½® y è½´åˆ»åº¦æ ‡ç­¾ï¼ˆç‰¹å¾åç§°ï¼‰çš„å­—ä½“å¤§å°
plt.xticks(fontsize=12)  # è®¾ç½® y è½´åˆ»åº¦æ ‡ç­¾ï¼ˆç‰¹å¾åç§°ï¼‰çš„å­—ä½“å¤§å°
# åœ¨æ¯ä¸ªæ¡å½¢å†…éƒ¨æ·»åŠ æ•°å€¼
for bar in bars:
    value = bar.get_width()
    # åŠ¨æ€è°ƒæ•´å­—ä½“å¤§å°å’Œä½ç½®
    font_size = 12   # æ ¹æ®æŸ±å­å®½åº¦è°ƒæ•´å­—ä½“å¤§å°
    x_position = value - 0.02 if value > 0.05 else value + 0.01  # æ•°å€¼ä½ç½®
    plt.text(
        x_position,  # æ•°å€¼ä½ç½®ç¨å¾®åå³æˆ–åå·¦
        bar.get_y() + bar.get_height() / 2,  # æ¡å½¢ä¸­å¿ƒé«˜åº¦
        f'{value:.4f}',  # æ˜¾ç¤ºæ•°å€¼
        va='center', ha='right' if value > 0.05 else 'left', fontsize=font_size, color='white' if value > 0.05 else 'black'
    )

plt.gca().invert_yaxis()  # åè½¬ y è½´ï¼Œä½¿å¾—æœ€é‡è¦çš„ç‰¹å¾åœ¨ä¸Šé¢
plt.tight_layout()
plt.savefig('shap_barplot.png', dpi=300, bbox_inches='tight', pad_inches=0.1)
plt.show()
# ==========================
# 7. å¯¼å‡ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„çœŸå®å€¼ä¸é¢„æµ‹å€¼å¯¹æ¯”æ•°æ®
# ==========================
# åˆ›å»ºè®­ç»ƒé›†çš„ç»“æœè¡¨æ ¼
train_results_df = pd.DataFrame({
    "True Values (Train)": y_train.flatten(),
    "Predicted Values (Train)": xgb_train_preds.flatten(),
})

# åˆ›å»ºæµ‹è¯•é›†çš„ç»“æœè¡¨æ ¼
test_results_df = pd.DataFrame({
    "True Values (Test)": y_test.flatten(),
    "Predicted Values (Test)": xgb_test_preds.flatten(),
})

# åˆå¹¶è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç»“æœ
results_df = pd.concat([train_results_df, test_results_df], axis=1)

# ä¿å­˜ç»“æœ
results_df.to_csv("xgboost_results2.csv", index=False)
print("\nâœ… åŒ…å«è®­ç»ƒé›†ã€æµ‹è¯•é›†çœŸå®å€¼ä¸é¢„æµ‹å€¼çš„ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶ï¼šxgboost_results.csv")

